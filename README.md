# ğŸ¤– Multimodal AI Assistant

An intelligent assistant built with **GPT-4o**, capable of:

- ğŸ—£ï¸ Understanding and responding to **voice input** (using Whisper)
- ğŸ§  Generating natural replies with **OpenAI's GPT-4o**
- ğŸ–¼ï¸ Analyzing uploaded **images**
- ğŸŒ Performing **real-time web search** (via Google CSE)
- ğŸ”Š Replying back with **voice output** (using gTTS)

## ğŸš€ Live Demo
Coming soon...

## ğŸ”§ Features

- ğŸ¤ **Voice-to-Text**: Users can speak, and Whisper will transcribe the speech in real-time.
- ğŸ’¬ **Chat Interface**: Powered by GPT-4o for fluent, natural conversation.
- ğŸ–¼ï¸ **Image Analysis**: Upload an image and receive contextual visual analysis.
- ğŸ” **Web Search**: Automatically detects when current data is needed and performs a web search using Google Custom Search API.
- ğŸ”Š **Text-to-Speech**: AI responses are read aloud using Google Text-to-Speech (gTTS).

## ğŸ› ï¸ Tech Stack

- **Frontend/UI**: Gradio
- **Backend**: Python
- **AI Models**:
  - [OpenAI GPT-4o](https://platform.openai.com/)
  - [Whisper (Speech-to-Text)](https://github.com/openai/whisper)
  - [gTTS (Text-to-Speech)](https://pypi.org/project/gTTS/)
- **Real-time Search**: Google Custom Search API
- **Deployment Options**: Localhost / Hugging Face Spaces / Render / Colab

## ğŸ” Environment Variables

Create a `.env` or use secret manager with the following keys:

```bash
OPENAI_API_KEY=your_openai_key
GOOGLE_API_KEY=your_google_api_key
GOOGLE_CSE_ID=your_google_custom_search_engine_id
